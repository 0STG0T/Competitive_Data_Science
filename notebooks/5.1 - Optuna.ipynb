{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFlyZD8XZM_9"
   },
   "source": [
    "# Optuna\n",
    "\n",
    "Optuna — фреймворк для оптимизации поиска оптимальных гиперпараметров модели.\n",
    "\n",
    "В отличие от всем известного GridSearch'a Оптуна не перебирает все комбинации параметров, а использует более умный подход.\n",
    "\n",
    "Чтобы понять, как ее использовать, давайте разберем ее по частям.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgtRK_LIazK4"
   },
   "outputs": [],
   "source": [
    "!pip install optuna catboost -qqq\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3XjdnkAZj3K"
   },
   "source": [
    "## 1. Objective function\n",
    "В этой функции нужно написать код подсчета метрики, которую возвращаем. Objective вызывается Отпуной много раз для подбора лучших параметров.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK8n-u9QZvpI"
   },
   "outputs": [],
   "source": [
    "​def objective(trial, ...):\n",
    "    # calculate score...\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcJD36SJZqsY"
   },
   "source": [
    "## 2. Trial object\n",
    "В trial мы передаем параметры для \"перебора\", используя для каждого типа свой метод.\n",
    "\n",
    "К примеру,  trial.suggest_float('x', -10, 10) где метод suggest_float показывает, что перебираем в float значениях, а -10 и 10 стартовый и конечные шаги.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-fg0klZZte0"
   },
   "outputs": [],
   "source": [
    "# Категориальное значение\n",
    "loss_function = trial.suggest_categorical('loss', ['Logloss', 'CrossEntropy'])\n",
    "\n",
    "# Целочисленное значение\n",
    "depth = trial.suggest_int('depth', 5, 8)\n",
    "\n",
    "# Равномерное распределение\n",
    "learning_rate = trial.suggest_uniform('learning_rate', 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijA6SzMfaJNt"
   },
   "source": [
    "## 3. Study parameter\n",
    "Инициализируем обьект **study**, который начнет перебор и сохранит в себе историю результатов.\n",
    "Если мы стараемя увеличить метрику, а не уменьшить ошибку, то используем `create_study(direction='maximize')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFN53DmFZGu7"
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TggzN4viaPUb"
   },
   "source": [
    "## Итоговый код может выглядеть подобным образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcn49xVAaQ2k"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_params  # E.g. {'x': 2.002108042}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPrkCCZtamSl"
   },
   "source": [
    "## Давайте запустим Optuna на наших данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehU3CWJ8lNw6"
   },
   "source": [
    "Подгрузим данные и отберем колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_z60Tr5isnUt"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle -qqq\n",
    "!mkdir /root/.kaggle\n",
    "!cp /content/kaggle.json /root/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d ivanblch/competetive-course-contest-dataset\n",
    "!unzip competetive-course-contest-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VD1srqIKcjm7"
   },
   "outputs": [],
   "source": [
    "# path = '/kaggle/input/competative-data-science-course-by-data-feeling/car_train.csv'\n",
    "path = 'car_train.csv'\n",
    "car_train = pd.read_csv(path).drop('target_1', axis=1)\n",
    "\n",
    "features2drop = ['car_id'] \n",
    "targets = ['target_2']  \n",
    "cat_features = ['car_type', 'fuel_type', 'model'] \n",
    "\n",
    "filtered_features = [i for i in car_train.columns if (i not in targets and i not in features2drop)] #+ cat_features \n",
    "num_features = [i for i in filtered_features if i not in cat_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEJKzzkClRGv"
   },
   "source": [
    "Объявим функцию обучения Catboost с возращением предсказаний на Kfold валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rANLQ5xYlSxa"
   },
   "outputs": [],
   "source": [
    "def fit_catboost(trial, train, val):\n",
    "    X_train, y_train = train\n",
    "    X_val, y_val = val\n",
    "\n",
    "    param = {\n",
    "        #\"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.001, 0.01),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 2, 17),\n",
    "        #\"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        'auto_class_weights': trial.suggest_categorical('auto_class_weights', ['SqrtBalanced', \"Balanced\", 'None']),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 6, 12),\n",
    "        #\"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"used_ram_limit\": \"12gb\",\n",
    "    }\n",
    "\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    clf = CatBoostClassifier(**params)\n",
    "\n",
    "    clf.fit(X=X_train, y=y_train, eval_set=(X_val, y_val), verbose = 250, plot = False)\n",
    "\n",
    "    # инференс модели\n",
    "    # y_pred = np.zeros((X_val.shape[0], 9)) # массив для записи финального результата\n",
    "    y_pred = clf.predict(X_val)#[:,1]\n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0c975p_lcKT"
   },
   "source": [
    "Напишем функцию **objective** в которую поместим Kfold валидацию, чтобы подбирать лучшие гиперпараметры на всем датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qTZBwvWOaqFp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial, return_models=False):\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    X_train = car_train[filtered_features].drop(targets, axis=1, errors='ignore')\n",
    "    y_train = car_train[targets]\n",
    "\n",
    "    scores = []\n",
    "    models = []\n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        train_data = X_train.iloc[train_idx,:], y_train.iloc[train_idx]\n",
    "        valid_data = X_train.iloc[valid_idx,:], y_train.iloc[valid_idx]\n",
    "\n",
    "        model, y_pred = fit_catboost(trial, train_data, valid_data)\n",
    "        scores.append(accuracy_score(y_pred, valid_data[1]))\n",
    "        models.append(model)\n",
    "        \n",
    "    result = np.mean(scores)\n",
    "    if return_models:\n",
    "        return result, models\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnu8rVqHtTAy"
   },
   "source": [
    "Запускаем Optuna!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaBvIXCVtSKT"
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NneLk4keKee"
   },
   "source": [
    "Посмотрим на лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIbBgGXjbq5D"
   },
   "outputs": [],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrkqd77_lm8F"
   },
   "source": [
    "Обучим итоговые модели уже на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w68iw554f5N3"
   },
   "outputs": [],
   "source": [
    "valid_scores, models = objective(optuna.trial.FixedTrial(study.best_params), return_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkpL2-1Af7ii"
   },
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjNrWMGdgL5A"
   },
   "source": [
    "Чтобы посмотреть всю историю обучения можно вывести ее в виде датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kg4p-Bn7f9S2"
   },
   "outputs": [],
   "source": [
    "trials_df = study.trials_dataframe()\n",
    "trials_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-GdIj-Qk0Xb"
   },
   "source": [
    "Визуализация оптимизаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0Vb57qEk2t1"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU6epevrqbTX"
   },
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH-w4pM5qfK3"
   },
   "source": [
    "Pruning в Optuna — возможно останавливать оптимизацию параметров когда обучающая кривая становится хуже прошлых лучшых результатов.\n",
    "\n",
    "![Картинка](https://optuna.org/assets/img/pruning-example-with-caption.png)\n",
    "\n",
    "К сожалению, для Catboost'a нет встроенной в Оптуну функции, но есть для большинтва известных ML фреймворков. Например, таких как XGBoost и LightGBM.\n",
    "\n",
    "*   XGBoost: `optuna.integration.XGBoostPruningCallback`\n",
    "*   LightGBM: `optuna.integration.LightGBMPruningCallback`\n",
    "\n",
    "\n",
    "\n",
    "Для использования Pruning в Catboost можно использовать одну из общих вариаций, таких как `MedianPruner`.\n",
    "Функция прунинга просто добавляется в функцию `create_study` в параметр `pruner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9E_aZM3uqeCc"
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_S_NY3m9e__"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaKqJ4KIstQV"
   },
   "outputs": [],
   "source": [
    "# Вопросы\n",
    "# - В каком из примеров ошибка (например минимизация метрики)\n",
    "# - Выбрать наиболее правильный range из предоставленных параметров\n",
    "# - Интерактив с кодом: дать поподбирать параметры, чтобы достичь какую-то точность на датасете"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
